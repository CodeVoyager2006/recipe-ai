{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeVoyager2006/recipe-ai/blob/main/GenAI_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gen A.I Assignment\n",
        "by: Minh Son Truong/shen.truong2017@gmail.com\n",
        "##Setup Phase\n",
        "import the important libraries from Huggingface"
      ],
      "metadata": {
        "id": "FnMQC4ii9v5x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOKCy87GWo63"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEPF8StyJIBq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Load the flan-t5 model and tokenize it\n",
        "model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZycjaldUJRdd"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# Print out which device we're using (GPU or CPU)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the method to use the A.I model"
      ],
      "metadata": {
        "id": "ZwJVzacL-K7J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbrCNd0BJZ4y"
      },
      "outputs": [],
      "source": [
        "def recipe(text):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "  recipe_ids = model.generate(inputs[\"input_ids\"], max_length=128, num_beams=4, early_stopping=True)\n",
        "  return tokenizer.decode(recipe_ids[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBN3C0pDJ0Qh"
      },
      "outputs": [],
      "source": [
        "# Define a sample text for summarization\n",
        "sample_text =     \"\"\"\n",
        "chicken, pasta, tomato sauce\n",
        "\"\"\"\n",
        "\n",
        "# Summarize the sample text using the pre-trained model (without fine-tuning)\n",
        "pre_finetuned_recipe_generation = recipe(sample_text)\n",
        "print(\"recipe generation before fine-tuning:\", pre_finetuned_recipe_generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset\n",
        "- First import the library needed to load the dataset from hugging face\n",
        "\n",
        "\n",
        "- Then, load the database that will be used"
      ],
      "metadata": {
        "id": "bGLvhoAi-pTV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqoIc0Q7KqUs"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the CNN/DailyMail dataset, which contains articles and summaries\n",
        "dataset = load_dataset(\"Shengtao/recipe\", split=\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize\n",
        "tokenize the necessary data from the database"
      ],
      "metadata": {
        "id": "ez45R9ePAJAS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLUkAnkzLsfU"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "  # Extract the articles from the dataset\n",
        "  inputs = [ingredient for ingredient in examples['ingredients']]\n",
        "\n",
        "  # Tokenize the articles (inputs) with padding and truncation to a max length of 512\n",
        "  model_inputs = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "  # Tokenize the summaries (labels) using the target tokenizer context\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(examples['title'], max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "  # Attach the tokenized summaries as labels to the model inputs\n",
        "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "  # Move the tokenized inputs and labels to the appropriate device (GPU/CPU)\n",
        "  model_inputs = {k: v.to(device) for k, v in model_inputs.items()}\n",
        "\n",
        "  return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvhRgxf6MwLR"
      },
      "outputs": [],
      "source": [
        "# Tokenize the small training dataset\n",
        "tokenized_train_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up training arguments"
      ],
      "metadata": {
        "id": "oU8xpuzMATqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAgK7AxNREGb"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "# Define training arguments\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='./results',              # Directory to save the model checkpoints\n",
        "    evaluation_strategy=\"epoch\",         # Evaluate the model at the end of every epoch\n",
        "    learning_rate=2e-5,                  # Learning rate for the optimizer\n",
        "    per_device_train_batch_size=8,       # Batch size for training\n",
        "    per_device_eval_batch_size=8,        # Batch size for evaluation\n",
        "    weight_decay=0.01,                   # Regularization to prevent overfitting\n",
        "    save_total_limit=3,                  # Only keep the last 3 checkpoints\n",
        "    num_train_epochs=3,                  # Number of training epochs\n",
        "    predict_with_generate=True,          # Enable text generation during evaluation\n",
        "    logging_dir=\"./logs\"                 # Directory for storing training logs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the trainer object\n",
        "Using the Seq2SeqTrainer, we can train our model"
      ],
      "metadata": {
        "id": "dSQUUjcwAhRd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qX2sGybZI7N"
      },
      "outputs": [],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "# Create the trainer object\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,                         # The model to be trained\n",
        "    args=training_args,                  # The training arguments defined earlier\n",
        "    train_dataset=tokenized_train_dataset,  # The tokenized training dataset\n",
        "    tokenizer=tokenizer                  # The tokenizer to handle input and output\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8CP_wnMDZKvt"
      },
      "outputs": [],
      "source": [
        "# Let's train\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "Evaluate the metrics belong to our model post train"
      ],
      "metadata": {
        "id": "PmNu4ztWAp7o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkxb-d49ZkWK"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the evaluation dataset\n",
        "metrics = trainer.evaluate()\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final test\n",
        "- Set up the recipe method again to be called\n",
        "- Run test"
      ],
      "metadata": {
        "id": "c4Fh-NSWAu5n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMtLFsOcaRtn"
      },
      "outputs": [],
      "source": [
        "def recipe(text):\n",
        "  inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "  recipe_ids = model.generate(inputs[\"input_ids\"], max_length=128, num_beams=4, early_stopping=True)\n",
        "  return tokenizer.decode(recipe_ids[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAnK46TZZ7sc"
      },
      "outputs": [],
      "source": [
        "print(recipe(\"\"\"\n",
        "1 (8 ounce) box elbow macaroni ; ¼ cup butter ; ¼ cup all-purpose flour ; ½ teaspoon salt ; ground black pepper to taste ; 2 cups milk ; 2 cups shredded Cheddar cheese\n",
        "\"\"\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNUgus8Gw9qUh7AjtxTF+BM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}